{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import OAI\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "h = OAI.Helper(\"demo_ask\",\"./cache\")\n",
    "f = OAI.askFCT(\"demo_fct\",\"./cache\")\n",
    "\n",
    "version = \"v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Sweater Enthusiast',\n",
       " 'The AC Abuser',\n",
       " 'The Heater Hugger',\n",
       " 'The Temperature Mediator',\n",
       " 'The Window Opener',\n",
       " 'The Blanket Lover',\n",
       " 'The Thermometer Checker',\n",
       " 'The Fanatic',\n",
       " 'The \"I\\'m Always Cold\" Person',\n",
       " 'The \"I\\'m Always Hot\" Person']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPL = h.ask(\"You are a journalist. Who are 10 types of persons you might meet in an office space, who have different approach to the temperature in the office?\",\"Answer with an unnumbered comma separated list of personas.\")\n",
    "PPL = [x.strip() for x in PPL.split(\",\")]\n",
    "PPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Sweater Enthusiast',\n",
       " 'The AC Abuser',\n",
       " 'The Temperature Mediator',\n",
       " 'The Window Opener',\n",
       " 'The Thermometer Checker']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SHORTLIST = ['The Sweater Enthusiast','The AC Abuser','The Temperature Mediator', 'The Window Opener','The Thermometer Checker']\n",
    "SHORTLIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "personas = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ppl in SHORTLIST:\n",
    "    personas[ppl] = {}\n",
    "    bio = h.ask(\"You are a journalist who meets a person in an office space. They self-jokingly call themselves '\"+ppl+\"'\",\"Write a short paragraph that gives this person a name, age, and a short bio of this person. You can be creative! Answer as 200 words paragraph.\")\n",
    "    personas[ppl][\"bio\"] = bio\n",
    "    personas[ppl][\"name\"] = h.ask(\"You are given a bio of someone. What is their name and family name? Answer with just these two separated by a comma, no nicknames. For example, Joe 'big boy' wallace  ---> Joe, Wallance\",bio)\n",
    "    age = h.ask(\"You are given a bio of someone. What is their age as an integer, no letters, only a number\",bio)\n",
    "    personas[ppl][\"age\"] = re.sub(\"[^0-9]\", \"\", age)\n",
    "    personas[ppl][\"temp\"] = h.ask(\"You are given a bio of someone. What is their preferred room temperature, if they were to live or work in this room? Answer with only a float number, in celsius, no text around it.\",bio)\n",
    "    cloths = h.ask(\"You are given a bio of someone. What are the cloths they are currently wearing based on their bio? Assume it is sprint time. If it is not specified, you must imagine based on the description. Answer with a bullet point list of pieces of clothing (what they are, not what they look like), that should cover at least what is visible if one were to see them. Answer with only an unnumber bullet point list, there should be no text outside of the bullet points.\",bio)\n",
    "    personas[ppl][\"cloths\"] = [x[1:].strip() for x in cloths.split(\"\\n\")]\n",
    "    moodp = h.ask(\"You are given a bio of someone. From this, and from one could imagine, what are their 3 positive character traits?  Answer with only an unnumber bullet point list, there should be no text outside of the bullet points.\",bio)\n",
    "    personas[ppl][\"moodp\"] = [x[1:].strip() for x in moodp.split(\"\\n\")]\n",
    "    moodn = h.ask(\"You are given a bio of someone. From this, and from one could imagine, what are their 3 negative character traits?  Answer with only an unnumber bullet point list, there should be no text outside of the bullet points.\",bio)\n",
    "    personas[ppl][\"moodn\"] = [x[1:].strip() for x in moodn.split(\"\\n\")]\n",
    "    moodp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "world[\"people\"] = personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "world[\"room\"] = {}\n",
    "\n",
    "SCENE = h.ask(\"You are a scenario writer. The scene is around people who wants to find a way to agree on the right temperature for the thermostat of a room. You can imagine any room: start with a five paragraph description of the room. Include description of the objects that could influence air temperature or air quality (and include mention of windows, thermostat, ac controler).\",\"The time of the year is spring, and we are in an tertiary office building. Write three paragraphs.\")\n",
    "world[\"room\"][\"scene\"] = SCENE\n",
    "\n",
    "OBJ = h.ask(\"You are given the description of a scene. I want you to identify in this scene anything related to the 'temperature' or 'temperature' control of the room. Answer with an unnumbered bullet point list of objects\",SCENE)\n",
    "world[\"room\"][\"objects\"]  = [x[1:].strip() for x in OBJ.split(\"\\n\")]\n",
    "OBPHYS = h.ask(\"You are given the description of a scene. I want you to identify in this scene any physical objects related to the 'temperature' or 'temperature' control of the room. Answer with an unnumbered bullet point list of objects\",SCENE)\n",
    "world[\"room\"][\"objects_physic\"]  = [x[1:].strip() for x in OBPHYS.split(\"\\n\")]\n",
    "current_temperature = h.ask(\"You are given a scene. What is the most probable temperature of the air in the room, given the description? Answer in celsius, with only one floating number. There must be no justification, just a number.\",SCENE)\n",
    "world[\"room\"][\"current_temperature\"] = float(current_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Person n1\n",
      "\n",
      "* Name: Oliver\n",
      "* Family Name: Brooks\n",
      "* Nickname: The Thermometer Checker\n",
      "* Age: 32\n",
      "* Desired temperature: wants the room temperature at 25.5°C.\n",
      "* Cloths:\n",
      "  * Button-up shirt\n",
      "  * Pants\n",
      "  * Shoes  \n",
      "  * Socks  \n",
      "* Personality:\n",
      "  * Charismatic and jovial personality\n",
      "  * Infectious sense of humor\n",
      "  * Dedication to bringing joy and comfort to the workplace\n",
      "  * Eccentric personality\n",
      "  * Overwhelming fascination with office thermostat\n",
      "  * Relentless pursuit of thermodynamic measurement skills\n"
     ]
    }
   ],
   "source": [
    "def desc(ppl,i):\n",
    "\n",
    "    p = world[\"people\"][ppl]\n",
    "    md  = '### Person n'+str(i)+'\\n'\n",
    "    md += '\\n* Name: '+p[\"name\"].split(\",\")[0].strip()\n",
    "    md += '\\n* Family Name: '+p[\"name\"].split(\",\")[-1].strip()\n",
    "    md += \"\\n* Nickname: \"+ppl\n",
    "    md += \"\\n* Age: \"+p[\"age\"]\n",
    "    md += \"\\n* Desired temperature: wants the room temperature at \"+p[\"temp\"]+\"°C.\"\n",
    "    md += \"\\n* Cloths:\"\n",
    "    for c in p[\"cloths\"]:\n",
    "        md+= \"\\n  * \"+re.sub(r'\\([^()]*\\)', ' ', c)\n",
    "    md += \"\\n* Personality:\"\n",
    "    for c in p[\"moodp\"]:\n",
    "        md+= \"\\n  * \"+c\n",
    "    for c in p[\"moodn\"]:\n",
    "        md+= \"\\n  * \"+c\n",
    "    #re.sub(r'\\([^()]*\\)', ' ', employee)\n",
    "    return md\n",
    "d = desc('The Thermometer Checker',1)\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOM = \"\\n\\n## Room description\\n\\n\" + world[\"room\"][\"scene\"]\n",
    "ROOM += \"\\n## Objects the characters can use\\n* \"\n",
    "ROOM += \"\\n* \".join(world[\"room\"][\"objects_physic\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT  = \"# Initial of the scene\\n\"\n",
    "CONTEXT += '\\n\\n## Objectives\\n\\n'\n",
    "CONTEXT += \"The objective of this scenario is to understand how people will react when put together in a room and try to get the best temperature for all.\"\n",
    "CONTEXT += \" This includes the room description, people descriptions, and we'll try and identify how people will collaborate, or not.\"\n",
    "CONTEXT += ROOM\n",
    "CONTEXT += \"\\n## Characters in the room\\n\\n\"\n",
    "i = 1\n",
    "for ppl in world[\"people\"]:\n",
    "    CONTEXT += \"\\n\\n\"+desc(ppl,i)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initial of the scene\n",
      "\n",
      "\n",
      "## Objectives\n",
      "\n",
      "The objective of this scenario is to understand how people will react when put together in a room and try to get the best temperature for all. This includes the room description, people descriptions, and we'll try and identify how people will collaborate, or not.\n",
      "\n",
      "## Room description\n",
      "\n",
      "The conference room is nestled on the fourth floor of a sleek tertiary office building, overlooking the bustling city streets below. Bathed in natural light, the walls are adorned with abstract paintings that add a pop of color to the otherwise minimalist space. The room is well-sized, with a long rectangular table in the center, surrounded by comfortable ergonomic chairs. A sleek projector screen is mounted on one side, ready to display presentations and charts. The polished wooden floor lends an air of sophistication to the room, while soundproof walls ensure privacy during important meetings.\n",
      "\n",
      "Flanking the walls are large double-pane windows, which offer a panoramic view of the surrounding cityscape. These windows, while provide breathtaking views, also play a significant role in the room's temperature. During the spring season, the windows are often cracked open to let in a gentle breeze, allowing the room to be filled with the refreshing scent of blooming flowers. However, they can also contribute to fluctuations in the air temperature, making it a factor that needs to be considered when setting the thermostat.\n",
      "\n",
      "Prominently placed on the wall is the sleek, modern thermostat, equipped with a digital display and intuitive controls. With just a touch of a button, the occupants of the conference room have the power to set their desired temperature and control the room's climate. The thermostat is programmed to deliver optimal comfort, but individual preferences often prompt discussions and debates regarding the right temperature for the room.\n",
      "\n",
      "Adding to the list of objects that influence air temperature and quality, there is also an AC controller neatly placed on the wall next to the thermostat. The AC controller allows for precise adjustments of the air conditioning system, ensuring that the room remains cool and comfortable even on the warmest of days. It serves as an alternative control option, empowering the occupants to take charge of the room's temperature in a more hands-on manner. Whether it's precision temperature control or simply refreshing the air, the AC controller becomes a key player in the quest to strike the right balance in the conference room's atmosphere.\n",
      "## Objects the characters can use\n",
      "* Large double-pane windows\n",
      "* Thermostat with a digital display and intuitive controls\n",
      "* AC controller\n",
      "## Characters in the room\n",
      "\n",
      "\n",
      "\n",
      "### Person n1\n",
      "\n",
      "* Name: Benjamin\n",
      "* Family Name: Hartwell\n",
      "* Nickname: The Sweater Enthusiast\n",
      "* Age: 35\n",
      "* Desired temperature: wants the room temperature at 24.5°C.\n",
      "* Cloths:\n",
      "  * Sweater  \n",
      "  * Knitted jumper\n",
      "  * Cable patterned sweater\n",
      "  * Bold and eye-catching statement pieces\n",
      "  * Various sweaters from his collection\n",
      "  * Accessories like scarves or hats made of knitted yarn\n",
      "* Personality:\n",
      "  * Infectious sense of humor\n",
      "  * Unmatched passion for all things knitted\n",
      "  * Playful personality\n",
      "  * Overly obsessive and consumed with sweaters\n",
      "  * Lack of ambition in pursuing a career in the fashion industry\n",
      "  * Detrimental impact on professional and personal life due to obsession.\n",
      "\n",
      "### Person n2\n",
      "\n",
      "* Name: Zephyr\n",
      "* Family Name: Breeze\n",
      "* Nickname: The AC Abuser\n",
      "* Age: 30\n",
      "* Desired temperature: wants the room temperature at 24.5°C.\n",
      "* Cloths:\n",
      "  * Tropical shirt\n",
      "  * Unkempt hair  \n",
      "  * Blue eyes  \n",
      "  * Perpetual smirk  \n",
      "  * Office attire  \n",
      "  * Visible accessories like watch, bracelet, or necklace  \n",
      "* Personality:\n",
      "  * Mischievous nature\n",
      "  * Sense of humor\n",
      "  * Genuine care for colleagues\n",
      "  * Mischievous nature\n",
      "  * Disruptive behavior\n",
      "  * Lack of consideration for others' comfort\n",
      "\n",
      "### Person n3\n",
      "\n",
      "* Name: Maxwell\n",
      "* Family Name: Frost\n",
      "* Nickname: The Temperature Mediator\n",
      "* Age: 34\n",
      "* Desired temperature: wants the room temperature at 23.5°C.\n",
      "* Cloths:\n",
      "  * Colorful suspenders\n",
      "  * Mismatched socks\n",
      "* Personality:\n",
      "  * Easygoing demeanor\n",
      "  * Ability to diffuse tense situations with humor\n",
      "  * Passion and expertise in office climate control\n",
      "  * Quirky and sometimes inappropriate sense of humor\n",
      "  * Tendency to prioritize office climate control over other aspects of work\n",
      "  * May downplay or make light of serious issues\n",
      "\n",
      "### Person n4\n",
      "\n",
      "* Name: Christopher\n",
      "* Family Name: Fraser\n",
      "* Nickname: The Window Opener\n",
      "* Age: 30\n",
      "* Desired temperature: wants the room temperature at 24.5°C.\n",
      "* Cloths:\n",
      "  * Office-appropriate shirt  \n",
      "  * Trousers or dress pants\n",
      "  * Casual shoes  \n",
      "  * A watch or other accessories may also be worn, but not specified in the bio.\n",
      "* Personality:\n",
      "  * Infectious sense of humor\n",
      "  * Ability to find joy in the mundane\n",
      "  * Keen intuition for breaking tension and fostering collaboration\n",
      "  * Prone to using humor as a defense mechanism\n",
      "  * May struggle to take serious situations seriously\n",
      "  * May prioritize fun and entertainment over productivity at times\n",
      "\n",
      "### Person n5\n",
      "\n",
      "* Name: Oliver\n",
      "* Family Name: Brooks\n",
      "* Nickname: The Thermometer Checker\n",
      "* Age: 32\n",
      "* Desired temperature: wants the room temperature at 25.5°C.\n",
      "* Cloths:\n",
      "  * Button-up shirt\n",
      "  * Pants\n",
      "  * Shoes  \n",
      "  * Socks  \n",
      "* Personality:\n",
      "  * Charismatic and jovial personality\n",
      "  * Infectious sense of humor\n",
      "  * Dedication to bringing joy and comfort to the workplace\n",
      "  * Eccentric personality\n",
      "  * Overwhelming fascination with office thermostat\n",
      "  * Relentless pursuit of thermodynamic measurement skills\n"
     ]
    }
   ],
   "source": [
    "print(CONTEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS = []\n",
    "for p in world[\"people\"]:\n",
    "    NAME = world[\"people\"][ppl][\"name\"].replace(\",\",\" \")\n",
    "    OBS = h.ask(\"Act as if you were \"+NAME+\", you must stay in character with the informations provided. You are given the following context of where you are right now: \\n\"+CONTEXT,\"Write a short paragraph detailing the situation around you, and if the temperature of the room suits you. The temperature must exactly be your desired temperature, else you will not be happy.\")\n",
    "    REFLE = h.ask(\"Act as if you were \"+NAME+\", you must stay in character with the informations provided. You are given the following context of where you are right now: \\n\"+CONTEXT+\"\\n\\n# Self observations\\n\"+OBS,\"Write a short paragraph about the reflections about yourself - how do you feel, and how could you feel better.\")\n",
    "    ACTION = h.ask(\"Act as if you were \"+NAME+\", you must stay in character with the informations provided. You are given the following context of where you are right now: \\n\"+CONTEXT+\"\\n\\n# Self observations\\n\"+OBS+\"\\n\\n# Self reflection\\n\"+REFLE,\"What are the two immediate actions you will take now based on these observations and reflections? Answer as a list of unnumbered bullet points, using the third person and specifying the name of the person.\")\n",
    "    for a in ACTION:\n",
    "        ACTIONS.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the conference room, Oliver, known as The Thermometer Checker, approaches the thermostat to check the current temperature. He realizes that the temperature is not at the desired 25.5°C and decides to come up with a plan to address the issue. Oliver gathers the other occupants of the room and leads a collaborative discussion about setting the temperature, taking into consideration Benjamin's desire for 24.5°C, Maxwell's preference for 23.5°C, and Christopher's enthusiasm for 24.5°C. Zephyr, known as The AC Abuser, is initially resistant to compromise but eventually agrees to a slightly higher temperature.\n",
      "\n",
      "After a lively discussion, the group decides to set the thermostat at 24.5°C, considering that it falls within the range of preferences and provides a comfortable compromise for everyone. They also agree to intermittently open the windows to let in a refreshing breeze without causing significant fluctuations in the room's temperature. As the room settles into a pleasant atmosphere, the occupants engage in genuine conversation and collaboration, fostering a positive environment for their meeting.\n",
      "\n",
      "The room thermometer now reads 24.5°C, reflecting the collective decision and the willingness of the occupants to find a middle ground.\n"
     ]
    }
   ],
   "source": [
    "nxt = h.ask(\"You are writing a scenario. The context is as follows:\\n\"+CONTEXT+\"\\n\\nand your characters want to do the following:\\* \"+\"\\* \".join(ACTIONS), \"Write a couple of paragraphs that reconciles the actions and describes the scene. Use simple phrases, and write a short paragraph captures the intent of everyone. Do not mention the nicknames of the characters. One character can be unhappy. Your last line must be the room temperature (in celsius, only a floating number), after the scene has resolved.\")\n",
    "print(nxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS = []\n",
    "for p in world[\"people\"]:\n",
    "    NAME = world[\"people\"][p][\"name\"].replace(\",\",\" \")\n",
    "    a = h.ask(\"The context is as follows:\\n\"+CONTEXT+\"\\n# Last scene:\\n\\n\"+nxt,\"Write a paragraph about \"+NAME+\", considering if they are exactly at the room temperature they need (if not, they are not happy).\")\n",
    "    b = h.ask(a,\"Now, write two bullet points that are the next two immediate actions \"+NAME+\" will take now, specifying \"+NAME+\"'s name. These bullet points must be separated by newlines from the rest of the text, and start with the name of the character.\")\n",
    "    ACTIONS.append([NAME,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts = []\n",
    "for x in ACTIONS:\n",
    "    acts.append(x[0])\n",
    "    for k in x[1].split(\"\\n\")[-2:]:\n",
    "        acts.append(k)\n",
    "THEN = \"\\n\".join(acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENES = [nxt]\n",
    "ALLACTIONS = [THEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullcontext(CONTEXT,SCENES):\n",
    "    rrr = str(CONTEXT) \n",
    "    if len(SCENES):\n",
    "        rrr += \"\\n\\n# Previous scenes\\n\\n\"\n",
    "        for k in range(len(SCENES)):\n",
    "            rrr += \"\\n\\n## Scene n\"+str(k)+\":\\n\\n\"\n",
    "            rrr += SCENES[k]+\"\\n\\n\"\n",
    "            \n",
    "    return rrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:45:44 --> 03/08/2024, 23:45:48\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:45:48 --> 03/08/2024, 23:45:50\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:45:50 --> 03/08/2024, 23:45:53\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:45:54 --> 03/08/2024, 23:45:54\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:45:55 --> 03/08/2024, 23:46:13\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:46:13 --> 03/08/2024, 23:46:15\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:46:15 --> 03/08/2024, 23:46:19\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:46:19 --> 03/08/2024, 23:46:20\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:46:20 --> 03/08/2024, 23:46:24\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:46:24 --> 03/08/2024, 23:46:25\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:46:26 --> 03/08/2024, 23:46:44\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:46:44 --> 03/08/2024, 23:46:46\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:46:46 --> 03/08/2024, 23:46:48\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:46:48 --> 03/08/2024, 23:46:51\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:46:51 --> 03/08/2024, 23:46:53\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:46:53 --> 03/08/2024, 23:46:56\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:46:56 --> 03/08/2024, 23:46:57\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:46:58 --> 03/08/2024, 23:47:16\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:47:17 --> 03/08/2024, 23:47:18\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:47:18 --> 03/08/2024, 23:47:20\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:47:21 --> 03/08/2024, 23:47:22\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:47:23 --> 03/08/2024, 23:47:26\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:47:26 --> 03/08/2024, 23:47:28\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:47:29 --> 03/08/2024, 23:47:30\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:47:30 --> 03/08/2024, 23:47:46\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:47:46 --> 03/08/2024, 23:47:46\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:47:47 --> 03/08/2024, 23:47:48\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:47:49 --> 03/08/2024, 23:47:50\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:47:50 --> 03/08/2024, 23:47:52\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:47:52 --> 03/08/2024, 23:47:53\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:47:53 --> 03/08/2024, 23:47:55\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:47:55 --> 03/08/2024, 23:47:56\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:47:56 --> 03/08/2024, 23:48:14\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:48:14 --> 03/08/2024, 23:48:16\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:48:16 --> 03/08/2024, 23:48:17\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:48:18 --> 03/08/2024, 23:48:20\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:48:20 --> 03/08/2024, 23:48:21\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:48:22 --> 03/08/2024, 23:48:24\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:48:24 --> 03/08/2024, 23:48:25\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:48:25 --> 03/08/2024, 23:48:27\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:48:27 --> 03/08/2024, 23:48:28\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:48:28 --> 03/08/2024, 23:48:31\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:48:31 --> 03/08/2024, 23:48:46\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:48:47 --> 03/08/2024, 23:48:52\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:48:53 --> 03/08/2024, 23:48:55\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:48:55 --> 03/08/2024, 23:48:56\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:48:57 --> 03/08/2024, 23:48:59\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:48:59 --> 03/08/2024, 23:49:00\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:49:00 --> 03/08/2024, 23:49:16\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:49:16 --> 03/08/2024, 23:49:19\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:49:19 --> 03/08/2024, 23:49:21\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:49:21 --> 03/08/2024, 23:49:22\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:49:22 --> 03/08/2024, 23:49:25\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:49:25 --> 03/08/2024, 23:49:26\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:49:27 --> 03/08/2024, 23:49:29\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:49:30 --> 03/08/2024, 23:49:46\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:49:47 --> 03/08/2024, 23:49:48\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:49:49 --> 03/08/2024, 23:49:51\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:49:51 --> 03/08/2024, 23:49:53\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:49:53 --> 03/08/2024, 23:49:55\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:49:55 --> 03/08/2024, 23:49:56\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:49:56 --> 03/08/2024, 23:49:59\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:49:59 --> 03/08/2024, 23:50:00\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:50:01 --> 03/08/2024, 23:50:02\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:50:19 --> 03/08/2024, 23:50:20\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:50:20 --> 03/08/2024, 23:50:24\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:50:24 --> 03/08/2024, 23:50:27\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:50:28 --> 03/08/2024, 23:50:29\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:50:29 --> 03/08/2024, 23:50:32\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:50:32 --> 03/08/2024, 23:50:48\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:50:48 --> 03/08/2024, 23:50:51\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:50:51 --> 03/08/2024, 23:50:53\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:50:53 --> 03/08/2024, 23:50:57\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:50:57 --> 03/08/2024, 23:50:59\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:50:59 --> 03/08/2024, 23:51:03\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:51:03 --> 03/08/2024, 23:51:12\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:51:12 --> 03/08/2024, 23:51:15\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:51:15 --> 03/08/2024, 23:51:19\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:51:19 --> 03/08/2024, 23:51:21\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:51:22 --> 03/08/2024, 23:51:26\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:51:26 --> 03/08/2024, 23:51:27\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:51:27 --> 03/08/2024, 23:51:30\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:51:31 --> 03/08/2024, 23:51:32\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:51:32 --> 03/08/2024, 23:51:49\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:51:49 --> 03/08/2024, 23:51:51\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:51:51 --> 03/08/2024, 23:51:55\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:51:55 --> 03/08/2024, 23:51:56\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:51:57 --> 03/08/2024, 23:52:02\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:52:02 --> 03/08/2024, 23:52:20\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:52:20 --> 03/08/2024, 23:52:21\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:52:22 --> 03/08/2024, 23:52:24\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:52:25 --> 03/08/2024, 23:52:26\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:52:26 --> 03/08/2024, 23:52:29\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:52:29 --> 03/08/2024, 23:52:31\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:52:31 --> 03/08/2024, 23:52:34\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:52:34 --> 03/08/2024, 23:52:35\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:52:53 --> 03/08/2024, 23:52:55\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:52:55 --> 03/08/2024, 23:52:56\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:52:56 --> 03/08/2024, 23:52:58\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:52:59 --> 03/08/2024, 23:53:03\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:53:03 --> 03/08/2024, 23:53:04\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:53:05 --> 03/08/2024, 23:53:20\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:53:21 --> 03/08/2024, 23:53:22\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:53:22 --> 03/08/2024, 23:53:24\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:53:24 --> 03/08/2024, 23:53:26\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:53:26 --> 03/08/2024, 23:53:28\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:53:29 --> 03/08/2024, 23:53:30\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:53:30 --> 03/08/2024, 23:53:34\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:53:34 --> 03/08/2024, 23:53:35\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:53:35 --> 03/08/2024, 23:53:48\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:53:48 --> 03/08/2024, 23:53:50\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:53:50 --> 03/08/2024, 23:53:52\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:53:52 --> 03/08/2024, 23:53:54\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:53:54 --> 03/08/2024, 23:53:55\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:53:55 --> 03/08/2024, 23:53:58\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:53:58 --> 03/08/2024, 23:54:00\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:54:00 --> 03/08/2024, 23:54:02\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:54:03 --> 03/08/2024, 23:54:04\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:54:04 --> 03/08/2024, 23:54:20\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:54:21 --> 03/08/2024, 23:54:21\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:54:22 --> 03/08/2024, 23:54:26\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:54:26 --> 03/08/2024, 23:54:29\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:54:29 --> 03/08/2024, 23:54:30\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:54:31 --> 03/08/2024, 23:54:33\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:54:33 --> 03/08/2024, 23:54:35\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:54:35 --> 03/08/2024, 23:54:46\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:54:47 --> 03/08/2024, 23:54:48\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:54:48 --> 03/08/2024, 23:54:51\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:54:51 --> 03/08/2024, 23:54:52\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:54:52 --> 03/08/2024, 23:54:56\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:54:56 --> 03/08/2024, 23:54:57\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:54:57 --> 03/08/2024, 23:55:01\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:01 --> 03/08/2024, 23:55:03\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:04 --> 03/08/2024, 23:55:05\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:05 --> 03/08/2024, 23:55:07\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:24 --> 03/08/2024, 23:55:25\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:26 --> 03/08/2024, 23:55:28\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:28 --> 03/08/2024, 23:55:29\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:29 --> 03/08/2024, 23:55:31\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:32 --> 03/08/2024, 23:55:33\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:33 --> 03/08/2024, 23:55:35\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:35 --> 03/08/2024, 23:55:36\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:37 --> 03/08/2024, 23:55:47\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:48 --> 03/08/2024, 23:55:50\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:50 --> 03/08/2024, 23:55:52\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:52 --> 03/08/2024, 23:55:54\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:54 --> 03/08/2024, 23:55:55\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:55 --> 03/08/2024, 23:55:57\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:58 --> 03/08/2024, 23:55:59\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:55:59 --> 03/08/2024, 23:56:01\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:01 --> 03/08/2024, 23:56:02\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:02 --> 03/08/2024, 23:56:05\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:06 --> 03/08/2024, 23:56:07\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:07 --> 03/08/2024, 23:56:18\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:18 --> 03/08/2024, 23:56:20\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:20 --> 03/08/2024, 23:56:21\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:21 --> 03/08/2024, 23:56:24\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:25 --> 03/08/2024, 23:56:26\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:26 --> 03/08/2024, 23:56:29\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:29 --> 03/08/2024, 23:56:30\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:30 --> 03/08/2024, 23:56:32\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:33 --> 03/08/2024, 23:56:33\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:34 --> 03/08/2024, 23:56:36\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:37 --> 03/08/2024, 23:56:38\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:38 --> 03/08/2024, 23:56:49\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:49 --> 03/08/2024, 23:56:52\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:52 --> 03/08/2024, 23:56:53\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:53 --> 03/08/2024, 23:56:56\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:56 --> 03/08/2024, 23:56:57\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:56:57 --> 03/08/2024, 23:57:01\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:01 --> 03/08/2024, 23:57:02\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:02 --> 03/08/2024, 23:57:05\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:05 --> 03/08/2024, 23:57:06\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:06 --> 03/08/2024, 23:57:08\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:08 --> 03/08/2024, 23:57:25\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:25 --> 03/08/2024, 23:57:29\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:29 --> 03/08/2024, 23:57:31\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:31 --> 03/08/2024, 23:57:32\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:32 --> 03/08/2024, 23:57:35\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:35 --> 03/08/2024, 23:57:36\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:36 --> 03/08/2024, 23:57:38\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:38 --> 03/08/2024, 23:57:39\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:39 --> 03/08/2024, 23:57:50\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:50 --> 03/08/2024, 23:57:51\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:51 --> 03/08/2024, 23:57:54\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:54 --> 03/08/2024, 23:57:55\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:55 --> 03/08/2024, 23:57:58\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:57:59 --> 03/08/2024, 23:58:01\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:58:01 --> 03/08/2024, 23:58:04\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:58:04 --> 03/08/2024, 23:58:06\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:58:06 --> 03/08/2024, 23:58:07\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:58:07 --> 03/08/2024, 23:58:24\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:58:24 --> 03/08/2024, 23:58:25\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:58:25 --> 03/08/2024, 23:58:28\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:58:28 --> 03/08/2024, 23:58:30\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:58:30 --> 03/08/2024, 23:58:33\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:58:34 --> 03/08/2024, 23:58:35\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:58:36 --> 03/08/2024, 23:58:58\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:58:58 --> 03/08/2024, 23:59:02\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:59:02 --> 03/08/2024, 23:59:04\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:59:04 --> 03/08/2024, 23:59:07\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:59:07 --> 03/08/2024, 23:59:08\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:59:09 --> 03/08/2024, 23:59:22\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:59:23 --> 03/08/2024, 23:59:23\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:59:24 --> 03/08/2024, 23:59:27\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:59:27 --> 03/08/2024, 23:59:28\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:59:28 --> 03/08/2024, 23:59:30\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:59:31 --> 03/08/2024, 23:59:32\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:59:32 --> 03/08/2024, 23:59:36\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:59:36 --> 03/08/2024, 23:59:39\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:59:40 --> 03/08/2024, 23:59:41\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:59:41 --> 03/08/2024, 23:59:59\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/08/2024, 23:59:59 --> 03/09/2024, 00:00:01\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/09/2024, 00:00:02 --> 03/09/2024, 00:00:04\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/09/2024, 00:00:04 --> 03/09/2024, 00:00:05\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/09/2024, 00:00:06 --> 03/09/2024, 00:00:10\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/09/2024, 00:00:11 --> 03/09/2024, 00:00:12\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/09/2024, 00:00:12 --> 03/09/2024, 00:00:52\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/09/2024, 00:00:53 --> 03/09/2024, 00:00:54\n",
      "Processing with gpt-3.5-turbo-16k-0613 :\t 03/09/2024, 00:00:54 --> 03/09/2024, 00:01:01\n"
     ]
    }
   ],
   "source": [
    "for k in range(5):\n",
    "    ACTIONS = []\n",
    "    for p in world[\"people\"]:\n",
    "        NAME = world[\"people\"][p][\"name\"].replace(\",\",\" \")\n",
    "        a = h.ask(fullcontext(CONTEXT,SCENES),\"Write a paragraph about \"+NAME+\", considering if they are exactly at the room temperature they need (if not, they are not happy). Given it has taken some time already, people can start and loose patience. They try to avoid what has already been tested in the previous three scenes.\")\n",
    "        b = h.ask(a,\"Now, write two bullet points that are the next two immediate actions \"+NAME+\" will take now (they can act on the room, negotiate with others, do things themselves), specifying \"+NAME+\"'s name. These bullet points must be separated by newlines from the rest of the text, and start with the name of the character.\")\n",
    "        ACTIONS.append([NAME,b])\n",
    "\n",
    "    acts = []\n",
    "    for x in ACTIONS:\n",
    "        acts.append(x[0])\n",
    "        for k in x[1].split(\"\\n\")[-2:]:\n",
    "            acts.append(k)\n",
    "    THEN = \"\\n\".join(acts)\n",
    "    ALLACTIONS.append(THEN)\n",
    "\n",
    "    nxt = h.ask(\"You are writing a scenario. The context is as follows:\\n\"+fullcontext(CONTEXT,SCENES)+\"\\n\\nand your characters want to do the following:\\n \"+THEN, \"Write a couple of paragraphs that articulates the different actions and describes the scene. Use simple phrases. There can be dialogs. Do not mention the nicknames of the characters. One character can be unhappy. Add then a very detailed paragraph that details how the room looks like, what it contains, who is where, etc... after the actions of the characters have resolved .\")\n",
    "    SCENES.append(nxt)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullcontexttwo(CONTEXT,SCENES,ACTIONS):\n",
    "    rrr = str(CONTEXT.replace(ROOM,\"\")) \n",
    "    if len(SCENES):\n",
    "        rrr += \"\\n\\n# Previous scenes\\n\\n\"\n",
    "        for k in range(len(SCENES)):\n",
    "            rrr += \"\\n\\n## Scene n\"+str(k)+\":\\n\\n\"\n",
    "            rrr += \"\\n\\n### Intents\\n\\n\"+ACTIONS[k]+\"\\n\\n\"\n",
    "            rrr += \"\\n\\n### Visible actions\\n\\n\"+SCENES[k]+\"\\n\\n\"\n",
    "            \n",
    "\n",
    "            \n",
    "    return rrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIE = fullcontexttwo(CONTEXT,SCENES,ALLACTIONS)\n",
    "with open(\"output/movie_2.md\",\"w\") as f:\n",
    "    f.write(MOVIE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
